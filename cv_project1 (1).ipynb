{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xgTd6seH4vX6"
   },
   "source": [
    "## **Face Mask Segmentation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q7xhzmf25PUm"
   },
   "source": [
    "**Mount Google drive**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "r0nBeqjhQ9fI",
    "outputId": "85058c22-f61d-4a7d-df73-8a2bda71b955"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kpjfk_uN5L4_"
   },
   "source": [
    "**Change current working directory to project folder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U2Ya2QgARXMD"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('drive/My Drive/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Sw2374bd5eSH"
   },
   "source": [
    "**Load the \"images.npy\" file from the Google drive**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bZdef0yVRlvc"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data = np.load('/content/drive/My Drive/images.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Adj5eFS8569X"
   },
   "source": [
    "**Checking the first two samples from the loaded \"image.npy\" file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "kPWNTj32RqZD",
    "outputId": "bb2b9c10-29ef-4fad-f243-3d652f8d8466"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[42 37 34]\n",
      "  [56 51 48]\n",
      "  [71 66 63]\n",
      "  ...\n",
      "  [23 33 34]\n",
      "  [26 36 37]\n",
      "  [28 38 39]]\n",
      "\n",
      " [[40 35 32]\n",
      "  [51 46 43]\n",
      "  [64 59 56]\n",
      "  ...\n",
      "  [27 36 35]\n",
      "  [24 33 32]\n",
      "  [26 35 34]]\n",
      "\n",
      " [[43 38 35]\n",
      "  [51 46 43]\n",
      "  [61 56 53]\n",
      "  ...\n",
      "  [28 30 27]\n",
      "  [33 35 32]\n",
      "  [35 37 34]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[56 47 40]\n",
      "  [57 48 41]\n",
      "  [61 52 45]\n",
      "  ...\n",
      "  [67 48 42]\n",
      "  [55 35 28]\n",
      "  [60 40 33]]\n",
      "\n",
      " [[53 44 37]\n",
      "  [54 45 38]\n",
      "  [57 48 41]\n",
      "  ...\n",
      "  [59 40 34]\n",
      "  [60 40 33]\n",
      "  [54 34 27]]\n",
      "\n",
      " [[53 44 37]\n",
      "  [54 45 38]\n",
      "  [57 48 41]\n",
      "  ...\n",
      "  [59 40 34]\n",
      "  [70 50 43]\n",
      "  [64 44 37]]]\n",
      "[{'label': ['Face'], 'notes': '', 'points': [{'x': 0.08615384615384615, 'y': 0.3063063063063063}, {'x': 0.1723076923076923, 'y': 0.45345345345345345}], 'imageWidth': 650, 'imageHeight': 333}, {'label': ['Face'], 'notes': '', 'points': [{'x': 0.583076923076923, 'y': 0.2912912912912913}, {'x': 0.6584615384615384, 'y': 0.46846846846846846}], 'imageWidth': 650, 'imageHeight': 333}]\n",
      "[[[207 216 227 255]\n",
      "  [206 216 227 255]\n",
      "  [207 216 227 255]\n",
      "  ...\n",
      "  [ 35  33  34 255]\n",
      "  [ 35  33  34 255]\n",
      "  [ 35  33  34 255]]\n",
      "\n",
      " [[207 216 227 255]\n",
      "  [207 216 227 255]\n",
      "  [207 216 227 255]\n",
      "  ...\n",
      "  [ 35  32  33 255]\n",
      "  [ 35  33  34 255]\n",
      "  [ 35  33  34 255]]\n",
      "\n",
      " [[207 216 227 255]\n",
      "  [207 216 227 255]\n",
      "  [207 215 227 255]\n",
      "  ...\n",
      "  [ 35  33  33 255]\n",
      "  [ 35  33  34 255]\n",
      "  [ 35  33  34 255]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 31  21  17 255]\n",
      "  [ 31  22  18 255]\n",
      "  [ 31  22  18 255]\n",
      "  ...\n",
      "  [  0   1   4 255]\n",
      "  [  0   1   4 255]\n",
      "  [  0   1   4 255]]\n",
      "\n",
      " [[ 31  22  18 255]\n",
      "  [ 31  22  18 255]\n",
      "  [ 31  22  18 255]\n",
      "  ...\n",
      "  [  0   1   4 255]\n",
      "  [  0   1   4 255]\n",
      "  [  0   1   4 255]]\n",
      "\n",
      " [[ 31  22  18 255]\n",
      "  [ 30  22  17 255]\n",
      "  [ 31  22  18 255]\n",
      "  ...\n",
      "  [  0   1   4 255]\n",
      "  [  0   1   4 255]\n",
      "  [  0   1   4 255]]]\n",
      "[{'label': ['Face'], 'notes': '', 'points': [{'x': 0.7053087757313109, 'y': 0.23260437375745527}, {'x': 0.7692307692307693, 'y': 0.36182902584493043}], 'imageWidth': 1280, 'imageHeight': 697}]\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "  for j in range(2):\n",
    "    print(data[i][j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UP5vh_jH6Q4X"
   },
   "source": [
    "**Checking the shape of one sample in the loaded \"image.npy\" file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "WoHVuVMzVGvi",
    "outputId": "13e84ff2-ce27-4304-c4da-440275ac3c31"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(337, 600, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[10][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HXK0aMMy6jxn"
   },
   "source": [
    "**Set image dimensions:**\n",
    "\n",
    "\n",
    "1.   Initialize image height to 224\n",
    "2.   Initialize image width to 224\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PpsvaQfaWZX7"
   },
   "outputs": [],
   "source": [
    "IMAGE_WIDTH = 224\n",
    "IMAGE_HEIGHT = 224"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jA_VjWVX642f"
   },
   "source": [
    "**Create features and labels**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fvSCXnjmWfL6"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from tensorflow.keras.applications.mobilenet import preprocess_input\n",
    "\n",
    "masks = np.zeros((int(data.shape[0]), IMAGE_HEIGHT, IMAGE_WIDTH))\n",
    "X_train = np.zeros((int(data.shape[0]), IMAGE_HEIGHT, IMAGE_WIDTH, 3))\n",
    "\n",
    "for index in range(data.shape[0]):\n",
    "  img = data[index][0]\n",
    "  img = cv2.resize(img, dsize=(IMAGE_HEIGHT, IMAGE_WIDTH), interpolation=cv2.INTER_CUBIC)\n",
    "  try:\n",
    "    img = img[:, :, :3]\n",
    "  except:\n",
    "    continue\n",
    "  X_train[index] = preprocess_input(np.array(img, dtype = np.float32))\n",
    "  for i in data[index][1]:\n",
    "    x1 = int(i[\"points\"][0]['x'] * IMAGE_WIDTH)\n",
    "    x2 = int(i[\"points\"][1]['x'] * IMAGE_WIDTH)\n",
    "    y1 = int(i[\"points\"][0]['y'] * IMAGE_HEIGHT)\n",
    "    y2 = int(i[\"points\"][1]['y'] * IMAGE_HEIGHT)\n",
    "    masks[index][y1:y2, x1:x2] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "35ZLQCZgd1gx"
   },
   "source": [
    "**Print the shape of X_train and mask array**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ENEyRgdldotw",
    "outputId": "385e4a93-e730-4fbb-dae4-c335b824cb7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X_train is: (409, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "# shape of X_train\n",
    "print(\"The shape of X_train is:\", X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "1_xXUZyRd7t3",
    "outputId": "7cc07528-0307-43db-ac2d-678b94f99395"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shaoe of masks array is: (409, 224, 224)\n"
     ]
    }
   ],
   "source": [
    "#shape of mask\n",
    "print(\"The shaoe of masks array is:\", masks.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_klXstMkeEm5"
   },
   "source": [
    "**Print a sample image and image array**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "wUE848uZd_cH",
    "outputId": "f2c112ba-e25f-4653-acae-841d75e5f16c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.98431373 -0.98431373 -0.98431373]\n",
      "  [-0.98431373 -0.98431373 -0.98431373]\n",
      "  [-0.98431373 -0.98431373 -0.98431373]\n",
      "  ...\n",
      "  [-1.         -1.         -1.        ]\n",
      "  [-1.         -1.         -1.        ]\n",
      "  [-1.         -1.         -1.        ]]\n",
      "\n",
      " [[-0.98431373 -0.98431373 -0.98431373]\n",
      "  [-0.98431373 -0.98431373 -0.98431373]\n",
      "  [-0.98431373 -0.98431373 -0.98431373]\n",
      "  ...\n",
      "  [-1.         -1.         -1.        ]\n",
      "  [-1.         -1.         -1.        ]\n",
      "  [-1.         -1.         -1.        ]]\n",
      "\n",
      " [[-0.98431373 -0.98431373 -0.98431373]\n",
      "  [-0.98431373 -0.98431373 -0.98431373]\n",
      "  [-0.98431373 -0.98431373 -0.98431373]\n",
      "  ...\n",
      "  [-1.         -1.         -1.        ]\n",
      "  [-1.         -1.         -1.        ]\n",
      "  [-1.         -1.         -1.        ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-1.         -1.         -1.        ]\n",
      "  [-1.         -1.         -1.        ]\n",
      "  [-1.         -1.         -1.        ]\n",
      "  ...\n",
      "  [-0.96862745 -0.96862745 -0.96862745]\n",
      "  [-0.96078432 -0.96078432 -0.96078432]\n",
      "  [-0.96078432 -0.96078432 -0.96078432]]\n",
      "\n",
      " [[-1.         -1.         -1.        ]\n",
      "  [-1.         -1.         -1.        ]\n",
      "  [-1.         -1.         -1.        ]\n",
      "  ...\n",
      "  [-0.96862745 -0.96862745 -0.96862745]\n",
      "  [-0.96078432 -0.96078432 -0.96078432]\n",
      "  [-0.95294118 -0.95294118 -0.95294118]]\n",
      "\n",
      " [[-1.         -1.         -1.        ]\n",
      "  [-1.         -1.         -1.        ]\n",
      "  [-1.         -1.         -1.        ]\n",
      "  ...\n",
      "  [-0.97647059 -0.97647059 -0.97647059]\n",
      "  [-0.96862745 -0.96862745 -0.96862745]\n",
      "  [-0.96078432 -0.96078432 -0.96078432]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7efecf5a7828>"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "n = 10\n",
    "print(X_train[n])\n",
    "pyplot.imshow(X_train[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "QT0ZrP-oeSBP",
    "outputId": "122b7435-e6d5-43f2-fa75-054f44904c76"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff8bf3c5940>"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.imshow(masks[n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ogBwjfxo7qg_"
   },
   "source": [
    "**Create the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dYcIIFFEqg9D"
   },
   "outputs": [],
   "source": [
    "# Import the libraries\n",
    "from tensorflow.keras.applications.mobilenet import MobileNet\n",
    "from tensorflow.keras.layers import Concatenate,UpSampling2D, Conv2D, Reshape\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BNeikKkHeeBP"
   },
   "outputs": [],
   "source": [
    "def create_model(trainable=True):\n",
    "  model = MobileNet(input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, 3), include_top=False, alpha=1.0 , weights=\"imagenet\")\n",
    "\n",
    "  for layer in model.layers:\n",
    "    layer.trainable = trainable\n",
    "\n",
    "  # Add all the UNET layers\n",
    "  block1 = model.input\n",
    "  block2 = model.get_layer(\"conv_pw_1_relu\").output\n",
    "  block3 = model.get_layer(\"conv_pw_3_relu\").output\n",
    "  block4 = model.get_layer(\"conv_pw_5_relu\").output\n",
    "  block5 = model.get_layer(\"conv_pw_11_relu\").output\n",
    "  block6 = model.get_layer(\"conv_pw_13_relu\").output\n",
    "\n",
    "  \n",
    "  x = Concatenate()([UpSampling2D()(block6), block5])\n",
    "  x = Concatenate()([UpSampling2D()(x), block4])\n",
    "  x = Concatenate()([UpSampling2D()(x), block3])\n",
    "  x = Concatenate()([UpSampling2D()(x), block2])\n",
    "  x = Concatenate()([UpSampling2D()(x), block1])\n",
    " \n",
    "  x= Conv2D(1, kernel_size=1, activation=\"sigmoid\")(x)\n",
    "  x= Reshape((IMAGE_HEIGHT, IMAGE_WIDTH))(x)\n",
    "\n",
    "  return Model(inputs=model.input, outputs=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PazThT7Q8K63"
   },
   "source": [
    "**Create Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "60YEQHWfEzWs",
    "outputId": "ccbd5d2c-5ba9-4b2d-9205-24d9a55626a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_224_tf_no_top.h5\n",
      "17227776/17225924 [==============================] - 0s 0us/step\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 225, 225, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 112, 112, 32) 864         conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 112, 112, 32) 128         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (ReLU)               (None, 112, 112, 32) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)     (None, 112, 112, 32) 288         conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormalizatio (None, 112, 112, 32) 128         conv_dw_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_1_relu (ReLU)           (None, 112, 112, 32) 0           conv_dw_1_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_1 (Conv2D)              (None, 112, 112, 64) 2048        conv_dw_1_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormalizatio (None, 112, 112, 64) 256         conv_pw_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_1_relu (ReLU)           (None, 112, 112, 64) 0           conv_pw_1_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_pad_2 (ZeroPadding2D)      (None, 113, 113, 64) 0           conv_pw_1_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)     (None, 56, 56, 64)   576         conv_pad_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormalizatio (None, 56, 56, 64)   256         conv_dw_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_2_relu (ReLU)           (None, 56, 56, 64)   0           conv_dw_2_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_2 (Conv2D)              (None, 56, 56, 128)  8192        conv_dw_2_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormalizatio (None, 56, 56, 128)  512         conv_pw_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_2_relu (ReLU)           (None, 56, 56, 128)  0           conv_pw_2_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)     (None, 56, 56, 128)  1152        conv_pw_2_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormalizatio (None, 56, 56, 128)  512         conv_dw_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_3_relu (ReLU)           (None, 56, 56, 128)  0           conv_dw_3_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_3 (Conv2D)              (None, 56, 56, 128)  16384       conv_dw_3_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormalizatio (None, 56, 56, 128)  512         conv_pw_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_3_relu (ReLU)           (None, 56, 56, 128)  0           conv_pw_3_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_pad_4 (ZeroPadding2D)      (None, 57, 57, 128)  0           conv_pw_3_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)     (None, 28, 28, 128)  1152        conv_pad_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormalizatio (None, 28, 28, 128)  512         conv_dw_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_4_relu (ReLU)           (None, 28, 28, 128)  0           conv_dw_4_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_4 (Conv2D)              (None, 28, 28, 256)  32768       conv_dw_4_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormalizatio (None, 28, 28, 256)  1024        conv_pw_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_4_relu (ReLU)           (None, 28, 28, 256)  0           conv_pw_4_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)     (None, 28, 28, 256)  2304        conv_pw_4_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormalizatio (None, 28, 28, 256)  1024        conv_dw_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_5_relu (ReLU)           (None, 28, 28, 256)  0           conv_dw_5_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_5 (Conv2D)              (None, 28, 28, 256)  65536       conv_dw_5_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormalizatio (None, 28, 28, 256)  1024        conv_pw_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_5_relu (ReLU)           (None, 28, 28, 256)  0           conv_pw_5_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_pad_6 (ZeroPadding2D)      (None, 29, 29, 256)  0           conv_pw_5_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)     (None, 14, 14, 256)  2304        conv_pad_6[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormalizatio (None, 14, 14, 256)  1024        conv_dw_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_6_relu (ReLU)           (None, 14, 14, 256)  0           conv_dw_6_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_6 (Conv2D)              (None, 14, 14, 512)  131072      conv_dw_6_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormalizatio (None, 14, 14, 512)  2048        conv_pw_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_6_relu (ReLU)           (None, 14, 14, 512)  0           conv_pw_6_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)     (None, 14, 14, 512)  4608        conv_pw_6_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormalizatio (None, 14, 14, 512)  2048        conv_dw_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_7_relu (ReLU)           (None, 14, 14, 512)  0           conv_dw_7_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_7 (Conv2D)              (None, 14, 14, 512)  262144      conv_dw_7_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormalizatio (None, 14, 14, 512)  2048        conv_pw_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_7_relu (ReLU)           (None, 14, 14, 512)  0           conv_pw_7_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)     (None, 14, 14, 512)  4608        conv_pw_7_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormalizatio (None, 14, 14, 512)  2048        conv_dw_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_8_relu (ReLU)           (None, 14, 14, 512)  0           conv_dw_8_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_8 (Conv2D)              (None, 14, 14, 512)  262144      conv_dw_8_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormalizatio (None, 14, 14, 512)  2048        conv_pw_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_8_relu (ReLU)           (None, 14, 14, 512)  0           conv_pw_8_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)     (None, 14, 14, 512)  4608        conv_pw_8_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormalizatio (None, 14, 14, 512)  2048        conv_dw_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_9_relu (ReLU)           (None, 14, 14, 512)  0           conv_dw_9_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_9 (Conv2D)              (None, 14, 14, 512)  262144      conv_dw_9_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormalizatio (None, 14, 14, 512)  2048        conv_pw_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_9_relu (ReLU)           (None, 14, 14, 512)  0           conv_pw_9_bn[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D)    (None, 14, 14, 512)  4608        conv_pw_9_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormalizati (None, 14, 14, 512)  2048        conv_dw_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_10_relu (ReLU)          (None, 14, 14, 512)  0           conv_dw_10_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_10 (Conv2D)             (None, 14, 14, 512)  262144      conv_dw_10_relu[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormalizati (None, 14, 14, 512)  2048        conv_pw_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_10_relu (ReLU)          (None, 14, 14, 512)  0           conv_pw_10_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D)    (None, 14, 14, 512)  4608        conv_pw_10_relu[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormalizati (None, 14, 14, 512)  2048        conv_dw_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_11_relu (ReLU)          (None, 14, 14, 512)  0           conv_dw_11_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_11 (Conv2D)             (None, 14, 14, 512)  262144      conv_dw_11_relu[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormalizati (None, 14, 14, 512)  2048        conv_pw_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_11_relu (ReLU)          (None, 14, 14, 512)  0           conv_pw_11_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_pad_12 (ZeroPadding2D)     (None, 15, 15, 512)  0           conv_pw_11_relu[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D)    (None, 7, 7, 512)    4608        conv_pad_12[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormalizati (None, 7, 7, 512)    2048        conv_dw_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_12_relu (ReLU)          (None, 7, 7, 512)    0           conv_dw_12_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_12 (Conv2D)             (None, 7, 7, 1024)   524288      conv_dw_12_relu[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormalizati (None, 7, 7, 1024)   4096        conv_pw_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_12_relu (ReLU)          (None, 7, 7, 1024)   0           conv_pw_12_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D)    (None, 7, 7, 1024)   9216        conv_pw_12_relu[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormalizati (None, 7, 7, 1024)   4096        conv_dw_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_dw_13_relu (ReLU)          (None, 7, 7, 1024)   0           conv_dw_13_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_13 (Conv2D)             (None, 7, 7, 1024)   1048576     conv_dw_13_relu[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormalizati (None, 7, 7, 1024)   4096        conv_pw_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv_pw_13_relu (ReLU)          (None, 7, 7, 1024)   0           conv_pw_13_bn[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d (UpSampling2D)    (None, 14, 14, 1024) 0           conv_pw_13_relu[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 14, 14, 1536) 0           up_sampling2d[0][0]              \n",
      "                                                                 conv_pw_11_relu[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 28, 28, 1536) 0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 28, 28, 1792) 0           up_sampling2d_1[0][0]            \n",
      "                                                                 conv_pw_5_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 56, 56, 1792) 0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 56, 56, 1920) 0           up_sampling2d_2[0][0]            \n",
      "                                                                 conv_pw_3_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 112, 112, 192 0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 112, 112, 198 0           up_sampling2d_3[0][0]            \n",
      "                                                                 conv_pw_1_relu[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 224, 224, 198 0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 224, 224, 198 0           up_sampling2d_4[0][0]            \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 224, 224, 1)  1988        concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 224, 224)     0           conv2d[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 3,230,852\n",
      "Trainable params: 3,208,964\n",
      "Non-trainable params: 21,888\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lYFRBe-NFwFb"
   },
   "source": [
    "**Dice Coefficient**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "efHZBXZmFSTq"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "def dice_coefficient(y_true, y_pred):\n",
    "    numerator = 2 * tf.reduce_sum(y_true * y_pred)\n",
    "    denominator = tf.reduce_sum(y_true + y_pred)\n",
    "\n",
    "    return numerator / (denominator + tf.keras.backend.epsilon())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wO9uwlAyGGSU"
   },
   "source": [
    "**Loss**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UR-WUEdCGCvC"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.backend import log, epsilon\n",
    "def loss(y_true, y_pred):\n",
    "    return binary_crossentropy(y_true, y_pred) - log(dice_coefficient(y_true, y_pred) + epsilon())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N66bui1dGnrt"
   },
   "source": [
    "**Compile the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XMgEIxr-Gamm"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "optimizer = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(loss=loss, optimizer=optimizer, metrics=[dice_coefficient])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3rPwNq3bHGOU"
   },
   "source": [
    "**Define checkpoint and earlystopping**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ah1aWBCoHDK_",
    "outputId": "e403f915-59a3-40ec-b7d7-7898b885ae0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint(\"model-{loss:.2f}.h5\", monitor=\"loss\", verbose=1, save_best_only=True,\n",
    "                             save_weights_only=True, mode=\"min\", period=1)\n",
    "stop = EarlyStopping(monitor=\"loss\", patience=5, mode=\"min\")\n",
    "reduce_lr = ReduceLROnPlateau(monitor=\"loss\", factor=0.2, patience=5, min_lr=1e-6, verbose=1, mode=\"min\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jIp7OxXQHvfI"
   },
   "source": [
    "**Fit the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "IcBUnUtGHroJ",
    "outputId": "3da81508-02a8-406d-aa0c-62cb9d49a971"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 1.3106 - dice_coefficient: 0.4492\n",
      "Epoch 00001: loss improved from inf to 1.31057, saving model to model-1.31.h5\n",
      "409/409 [==============================] - 537s 1s/step - loss: 1.3106 - dice_coefficient: 0.4492 - lr: 1.0000e-04\n",
      "Epoch 2/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.7977 - dice_coefficient: 0.6117\n",
      "Epoch 00002: loss improved from 1.31057 to 0.79774, saving model to model-0.80.h5\n",
      "409/409 [==============================] - 535s 1s/step - loss: 0.7977 - dice_coefficient: 0.6117 - lr: 1.0000e-04\n",
      "Epoch 3/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.6277 - dice_coefficient: 0.6752\n",
      "Epoch 00003: loss improved from 0.79774 to 0.62767, saving model to model-0.63.h5\n",
      "409/409 [==============================] - 534s 1s/step - loss: 0.6277 - dice_coefficient: 0.6752 - lr: 1.0000e-04\n",
      "Epoch 4/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.5876 - dice_coefficient: 0.6934\n",
      "Epoch 00004: loss improved from 0.62767 to 0.58762, saving model to model-0.59.h5\n",
      "409/409 [==============================] - 534s 1s/step - loss: 0.5876 - dice_coefficient: 0.6934 - lr: 1.0000e-04\n",
      "Epoch 5/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.5381 - dice_coefficient: 0.7134\n",
      "Epoch 00005: loss improved from 0.58762 to 0.53812, saving model to model-0.54.h5\n",
      "409/409 [==============================] - 535s 1s/step - loss: 0.5381 - dice_coefficient: 0.7134 - lr: 1.0000e-04\n",
      "Epoch 6/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.4885 - dice_coefficient: 0.7338\n",
      "Epoch 00006: loss improved from 0.53812 to 0.48854, saving model to model-0.49.h5\n",
      "409/409 [==============================] - 536s 1s/step - loss: 0.4885 - dice_coefficient: 0.7338 - lr: 1.0000e-04\n",
      "Epoch 7/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.4652 - dice_coefficient: 0.7463\n",
      "Epoch 00007: loss improved from 0.48854 to 0.46517, saving model to model-0.47.h5\n",
      "409/409 [==============================] - 534s 1s/step - loss: 0.4652 - dice_coefficient: 0.7463 - lr: 1.0000e-04\n",
      "Epoch 8/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.4488 - dice_coefficient: 0.7538\n",
      "Epoch 00008: loss improved from 0.46517 to 0.44884, saving model to model-0.45.h5\n",
      "409/409 [==============================] - 529s 1s/step - loss: 0.4488 - dice_coefficient: 0.7538 - lr: 1.0000e-04\n",
      "Epoch 9/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.4372 - dice_coefficient: 0.7608\n",
      "Epoch 00009: loss improved from 0.44884 to 0.43721, saving model to model-0.44.h5\n",
      "409/409 [==============================] - 534s 1s/step - loss: 0.4372 - dice_coefficient: 0.7608 - lr: 1.0000e-04\n",
      "Epoch 10/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.4270 - dice_coefficient: 0.7661\n",
      "Epoch 00010: loss improved from 0.43721 to 0.42700, saving model to model-0.43.h5\n",
      "409/409 [==============================] - 531s 1s/step - loss: 0.4270 - dice_coefficient: 0.7661 - lr: 1.0000e-04\n",
      "Epoch 11/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.4148 - dice_coefficient: 0.7716\n",
      "Epoch 00011: loss improved from 0.42700 to 0.41480, saving model to model-0.41.h5\n",
      "409/409 [==============================] - 526s 1s/step - loss: 0.4148 - dice_coefficient: 0.7716 - lr: 1.0000e-04\n",
      "Epoch 12/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.4062 - dice_coefficient: 0.7767\n",
      "Epoch 00012: loss improved from 0.41480 to 0.40622, saving model to model-0.41.h5\n",
      "409/409 [==============================] - 532s 1s/step - loss: 0.4062 - dice_coefficient: 0.7767 - lr: 1.0000e-04\n",
      "Epoch 13/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.3954 - dice_coefficient: 0.7819\n",
      "Epoch 00013: loss improved from 0.40622 to 0.39540, saving model to model-0.40.h5\n",
      "409/409 [==============================] - 536s 1s/step - loss: 0.3954 - dice_coefficient: 0.7819 - lr: 1.0000e-04\n",
      "Epoch 14/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.3905 - dice_coefficient: 0.7850\n",
      "Epoch 00014: loss improved from 0.39540 to 0.39048, saving model to model-0.39.h5\n",
      "409/409 [==============================] - 528s 1s/step - loss: 0.3905 - dice_coefficient: 0.7850 - lr: 1.0000e-04\n",
      "Epoch 15/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.3809 - dice_coefficient: 0.7899\n",
      "Epoch 00015: loss improved from 0.39048 to 0.38092, saving model to model-0.38.h5\n",
      "409/409 [==============================] - 525s 1s/step - loss: 0.3809 - dice_coefficient: 0.7899 - lr: 1.0000e-04\n",
      "Epoch 16/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.3688 - dice_coefficient: 0.7962\n",
      "Epoch 00016: loss improved from 0.38092 to 0.36881, saving model to model-0.37.h5\n",
      "409/409 [==============================] - 526s 1s/step - loss: 0.3688 - dice_coefficient: 0.7962 - lr: 1.0000e-04\n",
      "Epoch 17/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.3582 - dice_coefficient: 0.8023\n",
      "Epoch 00017: loss improved from 0.36881 to 0.35820, saving model to model-0.36.h5\n",
      "409/409 [==============================] - 529s 1s/step - loss: 0.3582 - dice_coefficient: 0.8023 - lr: 1.0000e-04\n",
      "Epoch 18/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.3469 - dice_coefficient: 0.8077\n",
      "Epoch 00018: loss improved from 0.35820 to 0.34687, saving model to model-0.35.h5\n",
      "409/409 [==============================] - 529s 1s/step - loss: 0.3469 - dice_coefficient: 0.8077 - lr: 1.0000e-04\n",
      "Epoch 19/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.3361 - dice_coefficient: 0.8139\n",
      "Epoch 00019: loss improved from 0.34687 to 0.33607, saving model to model-0.34.h5\n",
      "409/409 [==============================] - 526s 1s/step - loss: 0.3361 - dice_coefficient: 0.8139 - lr: 1.0000e-04\n",
      "Epoch 20/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.3282 - dice_coefficient: 0.8186\n",
      "Epoch 00020: loss improved from 0.33607 to 0.32816, saving model to model-0.33.h5\n",
      "409/409 [==============================] - 527s 1s/step - loss: 0.3282 - dice_coefficient: 0.8186 - lr: 1.0000e-04\n",
      "Epoch 21/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.3254 - dice_coefficient: 0.8203\n",
      "Epoch 00021: loss improved from 0.32816 to 0.32537, saving model to model-0.33.h5\n",
      "409/409 [==============================] - 527s 1s/step - loss: 0.3254 - dice_coefficient: 0.8203 - lr: 1.0000e-04\n",
      "Epoch 22/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.3155 - dice_coefficient: 0.8262\n",
      "Epoch 00022: loss improved from 0.32537 to 0.31545, saving model to model-0.32.h5\n",
      "409/409 [==============================] - 527s 1s/step - loss: 0.3155 - dice_coefficient: 0.8262 - lr: 1.0000e-04\n",
      "Epoch 23/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.3112 - dice_coefficient: 0.8287\n",
      "Epoch 00023: loss improved from 0.31545 to 0.31118, saving model to model-0.31.h5\n",
      "409/409 [==============================] - 532s 1s/step - loss: 0.3112 - dice_coefficient: 0.8287 - lr: 1.0000e-04\n",
      "Epoch 24/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.3083 - dice_coefficient: 0.8305\n",
      "Epoch 00024: loss improved from 0.31118 to 0.30826, saving model to model-0.31.h5\n",
      "409/409 [==============================] - 531s 1s/step - loss: 0.3083 - dice_coefficient: 0.8305 - lr: 1.0000e-04\n",
      "Epoch 25/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.3025 - dice_coefficient: 0.8336\n",
      "Epoch 00025: loss improved from 0.30826 to 0.30252, saving model to model-0.30.h5\n",
      "409/409 [==============================] - 532s 1s/step - loss: 0.3025 - dice_coefficient: 0.8336 - lr: 1.0000e-04\n",
      "Epoch 26/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.2976 - dice_coefficient: 0.8369\n",
      "Epoch 00026: loss improved from 0.30252 to 0.29759, saving model to model-0.30.h5\n",
      "409/409 [==============================] - 531s 1s/step - loss: 0.2976 - dice_coefficient: 0.8369 - lr: 1.0000e-04\n",
      "Epoch 27/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.2923 - dice_coefficient: 0.8399\n",
      "Epoch 00027: loss improved from 0.29759 to 0.29226, saving model to model-0.29.h5\n",
      "409/409 [==============================] - 529s 1s/step - loss: 0.2923 - dice_coefficient: 0.8399 - lr: 1.0000e-04\n",
      "Epoch 28/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.2886 - dice_coefficient: 0.8424\n",
      "Epoch 00028: loss improved from 0.29226 to 0.28859, saving model to model-0.29.h5\n",
      "409/409 [==============================] - 529s 1s/step - loss: 0.2886 - dice_coefficient: 0.8424 - lr: 1.0000e-04\n",
      "Epoch 29/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.2844 - dice_coefficient: 0.8445\n",
      "Epoch 00029: loss improved from 0.28859 to 0.28437, saving model to model-0.28.h5\n",
      "409/409 [==============================] - 530s 1s/step - loss: 0.2844 - dice_coefficient: 0.8445 - lr: 1.0000e-04\n",
      "Epoch 30/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.2801 - dice_coefficient: 0.8469\n",
      "Epoch 00030: loss improved from 0.28437 to 0.28014, saving model to model-0.28.h5\n",
      "409/409 [==============================] - 529s 1s/step - loss: 0.2801 - dice_coefficient: 0.8469 - lr: 1.0000e-04\n",
      "Epoch 31/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.2759 - dice_coefficient: 0.8496\n",
      "Epoch 00031: loss improved from 0.28014 to 0.27587, saving model to model-0.28.h5\n",
      "409/409 [==============================] - 530s 1s/step - loss: 0.2759 - dice_coefficient: 0.8496 - lr: 1.0000e-04\n",
      "Epoch 32/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.2723 - dice_coefficient: 0.8515\n",
      "Epoch 00032: loss improved from 0.27587 to 0.27231, saving model to model-0.27.h5\n",
      "409/409 [==============================] - 532s 1s/step - loss: 0.2723 - dice_coefficient: 0.8515 - lr: 1.0000e-04\n",
      "Epoch 33/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.2720 - dice_coefficient: 0.8523\n",
      "Epoch 00033: loss improved from 0.27231 to 0.27202, saving model to model-0.27.h5\n",
      "409/409 [==============================] - 531s 1s/step - loss: 0.2720 - dice_coefficient: 0.8523 - lr: 1.0000e-04\n",
      "Epoch 34/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.2732 - dice_coefficient: 0.8521\n",
      "Epoch 00034: loss did not improve from 0.27202\n",
      "409/409 [==============================] - 530s 1s/step - loss: 0.2732 - dice_coefficient: 0.8521 - lr: 1.0000e-04\n",
      "Epoch 35/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.2665 - dice_coefficient: 0.8555\n",
      "Epoch 00035: loss improved from 0.27202 to 0.26654, saving model to model-0.27.h5\n",
      "409/409 [==============================] - 529s 1s/step - loss: 0.2665 - dice_coefficient: 0.8555 - lr: 1.0000e-04\n",
      "Epoch 36/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.2610 - dice_coefficient: 0.8583\n",
      "Epoch 00036: loss improved from 0.26654 to 0.26103, saving model to model-0.26.h5\n",
      "409/409 [==============================] - 531s 1s/step - loss: 0.2610 - dice_coefficient: 0.8583 - lr: 1.0000e-04\n",
      "Epoch 37/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.2586 - dice_coefficient: 0.8598\n",
      "Epoch 00037: loss improved from 0.26103 to 0.25859, saving model to model-0.26.h5\n",
      "409/409 [==============================] - 531s 1s/step - loss: 0.2586 - dice_coefficient: 0.8598 - lr: 1.0000e-04\n",
      "Epoch 38/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.2568 - dice_coefficient: 0.8610\n",
      "Epoch 00038: loss improved from 0.25859 to 0.25676, saving model to model-0.26.h5\n",
      "409/409 [==============================] - 533s 1s/step - loss: 0.2568 - dice_coefficient: 0.8610 - lr: 1.0000e-04\n",
      "Epoch 39/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.2548 - dice_coefficient: 0.8621\n",
      "Epoch 00039: loss improved from 0.25676 to 0.25479, saving model to model-0.25.h5\n",
      "409/409 [==============================] - 531s 1s/step - loss: 0.2548 - dice_coefficient: 0.8621 - lr: 1.0000e-04\n",
      "Epoch 40/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.2552 - dice_coefficient: 0.8618\n",
      "Epoch 00040: loss did not improve from 0.25479\n",
      "409/409 [==============================] - 529s 1s/step - loss: 0.2552 - dice_coefficient: 0.8618 - lr: 1.0000e-04\n",
      "Epoch 41/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.2552 - dice_coefficient: 0.8623\n",
      "Epoch 00041: loss did not improve from 0.25479\n",
      "409/409 [==============================] - 528s 1s/step - loss: 0.2552 - dice_coefficient: 0.8623 - lr: 1.0000e-04\n",
      "Epoch 42/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.2496 - dice_coefficient: 0.8656\n",
      "Epoch 00042: loss improved from 0.25479 to 0.24964, saving model to model-0.25.h5\n",
      "409/409 [==============================] - 528s 1s/step - loss: 0.2496 - dice_coefficient: 0.8656 - lr: 1.0000e-04\n",
      "Epoch 43/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.2448 - dice_coefficient: 0.8681\n",
      "Epoch 00043: loss improved from 0.24964 to 0.24481, saving model to model-0.24.h5\n",
      "409/409 [==============================] - 529s 1s/step - loss: 0.2448 - dice_coefficient: 0.8681 - lr: 1.0000e-04\n",
      "Epoch 44/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.2414 - dice_coefficient: 0.8699\n",
      "Epoch 00044: loss improved from 0.24481 to 0.24138, saving model to model-0.24.h5\n",
      "409/409 [==============================] - 528s 1s/step - loss: 0.2414 - dice_coefficient: 0.8699 - lr: 1.0000e-04\n",
      "Epoch 45/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.2413 - dice_coefficient: 0.8702\n",
      "Epoch 00045: loss improved from 0.24138 to 0.24125, saving model to model-0.24.h5\n",
      "409/409 [==============================] - 527s 1s/step - loss: 0.2413 - dice_coefficient: 0.8702 - lr: 1.0000e-04\n",
      "Epoch 46/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.2396 - dice_coefficient: 0.8713\n",
      "Epoch 00046: loss improved from 0.24125 to 0.23965, saving model to model-0.24.h5\n",
      "409/409 [==============================] - 526s 1s/step - loss: 0.2396 - dice_coefficient: 0.8713 - lr: 1.0000e-04\n",
      "Epoch 47/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.2405 - dice_coefficient: 0.8709\n",
      "Epoch 00047: loss did not improve from 0.23965\n",
      "409/409 [==============================] - 527s 1s/step - loss: 0.2405 - dice_coefficient: 0.8709 - lr: 1.0000e-04\n",
      "Epoch 48/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.2417 - dice_coefficient: 0.8702\n",
      "Epoch 00048: loss did not improve from 0.23965\n",
      "409/409 [==============================] - 527s 1s/step - loss: 0.2417 - dice_coefficient: 0.8702 - lr: 1.0000e-04\n",
      "Epoch 49/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.2379 - dice_coefficient: 0.8723\n",
      "Epoch 00049: loss improved from 0.23965 to 0.23795, saving model to model-0.24.h5\n",
      "409/409 [==============================] - 528s 1s/step - loss: 0.2379 - dice_coefficient: 0.8723 - lr: 1.0000e-04\n",
      "Epoch 50/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.2329 - dice_coefficient: 0.8753\n",
      "Epoch 00050: loss improved from 0.23795 to 0.23294, saving model to model-0.23.h5\n",
      "409/409 [==============================] - 529s 1s/step - loss: 0.2329 - dice_coefficient: 0.8753 - lr: 1.0000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa8286515c0>"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x= X_train, y= masks, epochs=50, batch_size=1, verbose=1, callbacks = [checkpoint, stop, reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6fynR9i7r755"
   },
   "outputs": [],
   "source": [
    "# load the last saved weights\n",
    "model.load_weights('model-0.23.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "7QWweKbEsHRO",
    "outputId": "c31f1ac2-cebf-45fd-cda9-3a4b4ae4355b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.2295 - dice_coefficient: 0.8769\n",
      "Epoch 00001: loss improved from inf to 0.22954, saving model to model-0.23.h5\n",
      "409/409 [==============================] - 497s 1s/step - loss: 0.2295 - dice_coefficient: 0.8769 - lr: 1.0000e-04\n",
      "Epoch 2/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.2371 - dice_coefficient: 0.8733\n",
      "Epoch 00002: loss did not improve from 0.22954\n",
      "409/409 [==============================] - 486s 1s/step - loss: 0.2371 - dice_coefficient: 0.8733 - lr: 1.0000e-04\n",
      "Epoch 3/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.2337 - dice_coefficient: 0.8756\n",
      "Epoch 00003: loss did not improve from 0.22954\n",
      "409/409 [==============================] - 480s 1s/step - loss: 0.2337 - dice_coefficient: 0.8756 - lr: 1.0000e-04\n",
      "Epoch 4/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.2264 - dice_coefficient: 0.8793\n",
      "Epoch 00004: loss improved from 0.22954 to 0.22636, saving model to model-0.23.h5\n",
      "409/409 [==============================] - 494s 1s/step - loss: 0.2264 - dice_coefficient: 0.8793 - lr: 1.0000e-04\n",
      "Epoch 5/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.2241 - dice_coefficient: 0.8802\n",
      "Epoch 00005: loss improved from 0.22636 to 0.22413, saving model to model-0.22.h5\n",
      "409/409 [==============================] - 496s 1s/step - loss: 0.2241 - dice_coefficient: 0.8802 - lr: 1.0000e-04\n",
      "Epoch 6/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.2218 - dice_coefficient: 0.8818\n",
      "Epoch 00006: loss improved from 0.22413 to 0.22184, saving model to model-0.22.h5\n",
      "409/409 [==============================] - 505s 1s/step - loss: 0.2218 - dice_coefficient: 0.8818 - lr: 1.0000e-04\n",
      "Epoch 7/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.2197 - dice_coefficient: 0.8829\n",
      "Epoch 00007: loss improved from 0.22184 to 0.21966, saving model to model-0.22.h5\n",
      "409/409 [==============================] - 514s 1s/step - loss: 0.2197 - dice_coefficient: 0.8829 - lr: 1.0000e-04\n",
      "Epoch 8/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.2194 - dice_coefficient: 0.8831\n",
      "Epoch 00008: loss improved from 0.21966 to 0.21937, saving model to model-0.22.h5\n",
      "409/409 [==============================] - 519s 1s/step - loss: 0.2194 - dice_coefficient: 0.8831 - lr: 1.0000e-04\n",
      "Epoch 9/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.2186 - dice_coefficient: 0.8838\n",
      "Epoch 00009: loss improved from 0.21937 to 0.21858, saving model to model-0.22.h5\n",
      "409/409 [==============================] - 529s 1s/step - loss: 0.2186 - dice_coefficient: 0.8838 - lr: 1.0000e-04\n",
      "Epoch 10/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.2166 - dice_coefficient: 0.8850\n",
      "Epoch 00010: loss improved from 0.21858 to 0.21657, saving model to model-0.22.h5\n",
      "409/409 [==============================] - 531s 1s/step - loss: 0.2166 - dice_coefficient: 0.8850 - lr: 1.0000e-04\n",
      "Epoch 11/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.2149 - dice_coefficient: 0.8861\n",
      "Epoch 00011: loss improved from 0.21657 to 0.21487, saving model to model-0.21.h5\n",
      "409/409 [==============================] - 531s 1s/step - loss: 0.2149 - dice_coefficient: 0.8861 - lr: 1.0000e-04\n",
      "Epoch 12/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.2133 - dice_coefficient: 0.8870\n",
      "Epoch 00012: loss improved from 0.21487 to 0.21331, saving model to model-0.21.h5\n",
      "409/409 [==============================] - 536s 1s/step - loss: 0.2133 - dice_coefficient: 0.8870 - lr: 1.0000e-04\n",
      "Epoch 13/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.2124 - dice_coefficient: 0.8876\n",
      "Epoch 00013: loss improved from 0.21331 to 0.21237, saving model to model-0.21.h5\n",
      "409/409 [==============================] - 536s 1s/step - loss: 0.2124 - dice_coefficient: 0.8876 - lr: 1.0000e-04\n",
      "Epoch 14/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.2119 - dice_coefficient: 0.8880\n",
      "Epoch 00014: loss improved from 0.21237 to 0.21191, saving model to model-0.21.h5\n",
      "409/409 [==============================] - 535s 1s/step - loss: 0.2119 - dice_coefficient: 0.8880 - lr: 1.0000e-04\n",
      "Epoch 15/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.2125 - dice_coefficient: 0.8876\n",
      "Epoch 00015: loss did not improve from 0.21191\n",
      "409/409 [==============================] - 534s 1s/step - loss: 0.2125 - dice_coefficient: 0.8876 - lr: 1.0000e-04\n",
      "Epoch 16/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.2103 - dice_coefficient: 0.8892\n",
      "Epoch 00016: loss improved from 0.21191 to 0.21026, saving model to model-0.21.h5\n",
      "409/409 [==============================] - 534s 1s/step - loss: 0.2103 - dice_coefficient: 0.8892 - lr: 1.0000e-04\n",
      "Epoch 17/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.2073 - dice_coefficient: 0.8906\n",
      "Epoch 00017: loss improved from 0.21026 to 0.20728, saving model to model-0.21.h5\n",
      "409/409 [==============================] - 542s 1s/step - loss: 0.2073 - dice_coefficient: 0.8906 - lr: 1.0000e-04\n",
      "Epoch 18/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.2048 - dice_coefficient: 0.8920\n",
      "Epoch 00018: loss improved from 0.20728 to 0.20482, saving model to model-0.20.h5\n",
      "409/409 [==============================] - 537s 1s/step - loss: 0.2048 - dice_coefficient: 0.8920 - lr: 1.0000e-04\n",
      "Epoch 19/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.2037 - dice_coefficient: 0.8927\n",
      "Epoch 00019: loss improved from 0.20482 to 0.20374, saving model to model-0.20.h5\n",
      "409/409 [==============================] - 521s 1s/step - loss: 0.2037 - dice_coefficient: 0.8927 - lr: 1.0000e-04\n",
      "Epoch 20/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.2040 - dice_coefficient: 0.8926\n",
      "Epoch 00020: loss did not improve from 0.20374\n",
      "409/409 [==============================] - 516s 1s/step - loss: 0.2040 - dice_coefficient: 0.8926 - lr: 1.0000e-04\n",
      "Epoch 21/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.2031 - dice_coefficient: 0.8931\n",
      "Epoch 00021: loss improved from 0.20374 to 0.20311, saving model to model-0.20.h5\n",
      "409/409 [==============================] - 519s 1s/step - loss: 0.2031 - dice_coefficient: 0.8931 - lr: 1.0000e-04\n",
      "Epoch 22/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.2028 - dice_coefficient: 0.8937\n",
      "Epoch 00022: loss improved from 0.20311 to 0.20280, saving model to model-0.20.h5\n",
      "409/409 [==============================] - 518s 1s/step - loss: 0.2028 - dice_coefficient: 0.8937 - lr: 1.0000e-04\n",
      "Epoch 23/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.2011 - dice_coefficient: 0.8942\n",
      "Epoch 00023: loss improved from 0.20280 to 0.20114, saving model to model-0.20.h5\n",
      "409/409 [==============================] - 516s 1s/step - loss: 0.2011 - dice_coefficient: 0.8942 - lr: 1.0000e-04\n",
      "Epoch 24/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.2001 - dice_coefficient: 0.8951\n",
      "Epoch 00024: loss improved from 0.20114 to 0.20010, saving model to model-0.20.h5\n",
      "409/409 [==============================] - 514s 1s/step - loss: 0.2001 - dice_coefficient: 0.8951 - lr: 1.0000e-04\n",
      "Epoch 25/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.2001 - dice_coefficient: 0.8951\n",
      "Epoch 00025: loss improved from 0.20010 to 0.20007, saving model to model-0.20.h5\n",
      "409/409 [==============================] - 516s 1s/step - loss: 0.2001 - dice_coefficient: 0.8951 - lr: 1.0000e-04\n",
      "Epoch 26/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1993 - dice_coefficient: 0.8954\n",
      "Epoch 00026: loss improved from 0.20007 to 0.19928, saving model to model-0.20.h5\n",
      "409/409 [==============================] - 516s 1s/step - loss: 0.1993 - dice_coefficient: 0.8954 - lr: 1.0000e-04\n",
      "Epoch 27/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1971 - dice_coefficient: 0.8969\n",
      "Epoch 00027: loss improved from 0.19928 to 0.19711, saving model to model-0.20.h5\n",
      "409/409 [==============================] - 515s 1s/step - loss: 0.1971 - dice_coefficient: 0.8969 - lr: 1.0000e-04\n",
      "Epoch 28/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1961 - dice_coefficient: 0.8973\n",
      "Epoch 00028: loss improved from 0.19711 to 0.19607, saving model to model-0.20.h5\n",
      "409/409 [==============================] - 514s 1s/step - loss: 0.1961 - dice_coefficient: 0.8973 - lr: 1.0000e-04\n",
      "Epoch 29/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1952 - dice_coefficient: 0.8980\n",
      "Epoch 00029: loss improved from 0.19607 to 0.19520, saving model to model-0.20.h5\n",
      "409/409 [==============================] - 513s 1s/step - loss: 0.1952 - dice_coefficient: 0.8980 - lr: 1.0000e-04\n",
      "Epoch 30/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1935 - dice_coefficient: 0.8991\n",
      "Epoch 00030: loss improved from 0.19520 to 0.19349, saving model to model-0.19.h5\n",
      "409/409 [==============================] - 515s 1s/step - loss: 0.1935 - dice_coefficient: 0.8991 - lr: 1.0000e-04\n",
      "Epoch 31/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1931 - dice_coefficient: 0.8989\n",
      "Epoch 00031: loss improved from 0.19349 to 0.19312, saving model to model-0.19.h5\n",
      "409/409 [==============================] - 513s 1s/step - loss: 0.1931 - dice_coefficient: 0.8989 - lr: 1.0000e-04\n",
      "Epoch 32/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1936 - dice_coefficient: 0.8989\n",
      "Epoch 00032: loss did not improve from 0.19312\n",
      "409/409 [==============================] - 517s 1s/step - loss: 0.1936 - dice_coefficient: 0.8989 - lr: 1.0000e-04\n",
      "Epoch 33/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1930 - dice_coefficient: 0.8993\n",
      "Epoch 00033: loss improved from 0.19312 to 0.19298, saving model to model-0.19.h5\n",
      "409/409 [==============================] - 520s 1s/step - loss: 0.1930 - dice_coefficient: 0.8993 - lr: 1.0000e-04\n",
      "Epoch 34/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1928 - dice_coefficient: 0.8994\n",
      "Epoch 00034: loss improved from 0.19298 to 0.19284, saving model to model-0.19.h5\n",
      "409/409 [==============================] - 518s 1s/step - loss: 0.1928 - dice_coefficient: 0.8994 - lr: 1.0000e-04\n",
      "Epoch 35/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1927 - dice_coefficient: 0.8996\n",
      "Epoch 00035: loss improved from 0.19284 to 0.19273, saving model to model-0.19.h5\n",
      "409/409 [==============================] - 517s 1s/step - loss: 0.1927 - dice_coefficient: 0.8996 - lr: 1.0000e-04\n",
      "Epoch 36/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1888 - dice_coefficient: 0.9017\n",
      "Epoch 00036: loss improved from 0.19273 to 0.18883, saving model to model-0.19.h5\n",
      "409/409 [==============================] - 516s 1s/step - loss: 0.1888 - dice_coefficient: 0.9017 - lr: 1.0000e-04\n",
      "Epoch 37/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1873 - dice_coefficient: 0.9026\n",
      "Epoch 00037: loss improved from 0.18883 to 0.18728, saving model to model-0.19.h5\n",
      "409/409 [==============================] - 515s 1s/step - loss: 0.1873 - dice_coefficient: 0.9026 - lr: 1.0000e-04\n",
      "Epoch 38/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1868 - dice_coefficient: 0.9029\n",
      "Epoch 00038: loss improved from 0.18728 to 0.18678, saving model to model-0.19.h5\n",
      "409/409 [==============================] - 517s 1s/step - loss: 0.1868 - dice_coefficient: 0.9029 - lr: 1.0000e-04\n",
      "Epoch 39/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1861 - dice_coefficient: 0.9035\n",
      "Epoch 00039: loss improved from 0.18678 to 0.18609, saving model to model-0.19.h5\n",
      "409/409 [==============================] - 522s 1s/step - loss: 0.1861 - dice_coefficient: 0.9035 - lr: 1.0000e-04\n",
      "Epoch 40/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1866 - dice_coefficient: 0.9032\n",
      "Epoch 00040: loss did not improve from 0.18609\n",
      "409/409 [==============================] - 518s 1s/step - loss: 0.1866 - dice_coefficient: 0.9032 - lr: 1.0000e-04\n",
      "Epoch 41/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1871 - dice_coefficient: 0.9032\n",
      "Epoch 00041: loss did not improve from 0.18609\n",
      "409/409 [==============================] - 519s 1s/step - loss: 0.1871 - dice_coefficient: 0.9032 - lr: 1.0000e-04\n",
      "Epoch 42/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1864 - dice_coefficient: 0.9037\n",
      "Epoch 00042: loss did not improve from 0.18609\n",
      "409/409 [==============================] - 519s 1s/step - loss: 0.1864 - dice_coefficient: 0.9037 - lr: 1.0000e-04\n",
      "Epoch 43/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1854 - dice_coefficient: 0.9043\n",
      "Epoch 00043: loss improved from 0.18609 to 0.18541, saving model to model-0.19.h5\n",
      "409/409 [==============================] - 517s 1s/step - loss: 0.1854 - dice_coefficient: 0.9043 - lr: 1.0000e-04\n",
      "Epoch 44/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1848 - dice_coefficient: 0.9045\n",
      "Epoch 00044: loss improved from 0.18541 to 0.18476, saving model to model-0.18.h5\n",
      "409/409 [==============================] - 517s 1s/step - loss: 0.1848 - dice_coefficient: 0.9045 - lr: 1.0000e-04\n",
      "Epoch 45/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1839 - dice_coefficient: 0.9052\n",
      "Epoch 00045: loss improved from 0.18476 to 0.18391, saving model to model-0.18.h5\n",
      "409/409 [==============================] - 515s 1s/step - loss: 0.1839 - dice_coefficient: 0.9052 - lr: 1.0000e-04\n",
      "Epoch 46/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1828 - dice_coefficient: 0.9058\n",
      "Epoch 00046: loss improved from 0.18391 to 0.18280, saving model to model-0.18.h5\n",
      "409/409 [==============================] - 514s 1s/step - loss: 0.1828 - dice_coefficient: 0.9058 - lr: 1.0000e-04\n",
      "Epoch 47/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1832 - dice_coefficient: 0.9056\n",
      "Epoch 00047: loss did not improve from 0.18280\n",
      "409/409 [==============================] - 512s 1s/step - loss: 0.1832 - dice_coefficient: 0.9056 - lr: 1.0000e-04\n",
      "Epoch 48/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1841 - dice_coefficient: 0.9052\n",
      "Epoch 00048: loss did not improve from 0.18280\n",
      "409/409 [==============================] - 513s 1s/step - loss: 0.1841 - dice_coefficient: 0.9052 - lr: 1.0000e-04\n",
      "Epoch 49/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1830 - dice_coefficient: 0.9058\n",
      "Epoch 00049: loss did not improve from 0.18280\n",
      "409/409 [==============================] - 512s 1s/step - loss: 0.1830 - dice_coefficient: 0.9058 - lr: 1.0000e-04\n",
      "Epoch 50/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1812 - dice_coefficient: 0.9067\n",
      "Epoch 00050: loss improved from 0.18280 to 0.18119, saving model to model-0.18.h5\n",
      "409/409 [==============================] - 511s 1s/step - loss: 0.1812 - dice_coefficient: 0.9067 - lr: 1.0000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff8b7a56400>"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# contrinue training\n",
    "checkpoint = ModelCheckpoint(\"model-{loss:.2f}.h5\", monitor=\"loss\", verbose=1, save_best_only=True,\n",
    "                             save_weights_only=True, mode=\"min\", period=1)\n",
    "stop = EarlyStopping(monitor=\"loss\", patience=5, mode=\"min\")\n",
    "reduce_lr = ReduceLROnPlateau(monitor=\"loss\", factor=0.2, patience=5, min_lr=1e-6, verbose=1, mode=\"min\")\n",
    "\n",
    "model.fit(x= X_train, y= masks, epochs=50, batch_size=1, verbose=1, callbacks = [checkpoint, stop, reduce_lr])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Hx0yM6QhZWxA",
    "outputId": "bbdb25b0-1cfd-4381-aa1c-d2ef514afa00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1819 - dice_coefficient: 0.9062\n",
      "Epoch 00001: loss did not improve from 0.18119\n",
      "409/409 [==============================] - 512s 1s/step - loss: 0.1819 - dice_coefficient: 0.9062 - lr: 1.0000e-04\n",
      "Epoch 2/20\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1808 - dice_coefficient: 0.9070\n",
      "Epoch 00002: loss improved from 0.18119 to 0.18079, saving model to model-0.18.h5\n",
      "409/409 [==============================] - 515s 1s/step - loss: 0.1808 - dice_coefficient: 0.9070 - lr: 1.0000e-04\n",
      "Epoch 3/20\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1788 - dice_coefficient: 0.9081\n",
      "Epoch 00003: loss improved from 0.18079 to 0.17878, saving model to model-0.18.h5\n",
      "409/409 [==============================] - 517s 1s/step - loss: 0.1788 - dice_coefficient: 0.9081 - lr: 1.0000e-04\n",
      "Epoch 4/20\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1782 - dice_coefficient: 0.9085\n",
      "Epoch 00004: loss improved from 0.17878 to 0.17822, saving model to model-0.18.h5\n",
      "409/409 [==============================] - 513s 1s/step - loss: 0.1782 - dice_coefficient: 0.9085 - lr: 1.0000e-04\n",
      "Epoch 5/20\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1780 - dice_coefficient: 0.9085\n",
      "Epoch 00005: loss improved from 0.17822 to 0.17802, saving model to model-0.18.h5\n",
      "409/409 [==============================] - 513s 1s/step - loss: 0.1780 - dice_coefficient: 0.9085 - lr: 1.0000e-04\n",
      "Epoch 6/20\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1777 - dice_coefficient: 0.9090\n",
      "Epoch 00006: loss improved from 0.17802 to 0.17768, saving model to model-0.18.h5\n",
      "409/409 [==============================] - 512s 1s/step - loss: 0.1777 - dice_coefficient: 0.9090 - lr: 1.0000e-04\n",
      "Epoch 7/20\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1770 - dice_coefficient: 0.9093\n",
      "Epoch 00007: loss improved from 0.17768 to 0.17695, saving model to model-0.18.h5\n",
      "409/409 [==============================] - 512s 1s/step - loss: 0.1770 - dice_coefficient: 0.9093 - lr: 1.0000e-04\n",
      "Epoch 8/20\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1774 - dice_coefficient: 0.9091\n",
      "Epoch 00008: loss did not improve from 0.17695\n",
      "409/409 [==============================] - 511s 1s/step - loss: 0.1774 - dice_coefficient: 0.9091 - lr: 1.0000e-04\n",
      "Epoch 9/20\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1774 - dice_coefficient: 0.9093\n",
      "Epoch 00009: loss did not improve from 0.17695\n",
      "409/409 [==============================] - 510s 1s/step - loss: 0.1774 - dice_coefficient: 0.9093 - lr: 1.0000e-04\n",
      "Epoch 10/20\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1769 - dice_coefficient: 0.9095\n",
      "Epoch 00010: loss improved from 0.17695 to 0.17687, saving model to model-0.18.h5\n",
      "409/409 [==============================] - 512s 1s/step - loss: 0.1769 - dice_coefficient: 0.9095 - lr: 1.0000e-04\n",
      "Epoch 11/20\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1756 - dice_coefficient: 0.9104\n",
      "Epoch 00011: loss improved from 0.17687 to 0.17563, saving model to model-0.18.h5\n",
      "409/409 [==============================] - 512s 1s/step - loss: 0.1756 - dice_coefficient: 0.9104 - lr: 1.0000e-04\n",
      "Epoch 12/20\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1754 - dice_coefficient: 0.9104\n",
      "Epoch 00012: loss improved from 0.17563 to 0.17542, saving model to model-0.18.h5\n",
      "409/409 [==============================] - 511s 1s/step - loss: 0.1754 - dice_coefficient: 0.9104 - lr: 1.0000e-04\n",
      "Epoch 13/20\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1758 - dice_coefficient: 0.9101\n",
      "Epoch 00013: loss did not improve from 0.17542\n",
      "409/409 [==============================] - 509s 1s/step - loss: 0.1758 - dice_coefficient: 0.9101 - lr: 1.0000e-04\n",
      "Epoch 14/20\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1755 - dice_coefficient: 0.9105\n",
      "Epoch 00014: loss did not improve from 0.17542\n",
      "409/409 [==============================] - 508s 1s/step - loss: 0.1755 - dice_coefficient: 0.9105 - lr: 1.0000e-04\n",
      "Epoch 15/20\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1767 - dice_coefficient: 0.9097\n",
      "Epoch 00015: loss did not improve from 0.17542\n",
      "409/409 [==============================] - 509s 1s/step - loss: 0.1767 - dice_coefficient: 0.9097 - lr: 1.0000e-04\n",
      "Epoch 16/20\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1746 - dice_coefficient: 0.9108\n",
      "Epoch 00016: loss improved from 0.17542 to 0.17457, saving model to model-0.17.h5\n",
      "409/409 [==============================] - 512s 1s/step - loss: 0.1746 - dice_coefficient: 0.9108 - lr: 1.0000e-04\n",
      "Epoch 17/20\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1724 - dice_coefficient: 0.9119\n",
      "Epoch 00017: loss improved from 0.17457 to 0.17240, saving model to model-0.17.h5\n",
      "409/409 [==============================] - 512s 1s/step - loss: 0.1724 - dice_coefficient: 0.9119 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1710 - dice_coefficient: 0.9129\n",
      "Epoch 00018: loss improved from 0.17240 to 0.17099, saving model to model-0.17.h5\n",
      "409/409 [==============================] - 512s 1s/step - loss: 0.1710 - dice_coefficient: 0.9129 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1705 - dice_coefficient: 0.9132\n",
      "Epoch 00019: loss improved from 0.17099 to 0.17048, saving model to model-0.17.h5\n",
      "409/409 [==============================] - 514s 1s/step - loss: 0.1705 - dice_coefficient: 0.9132 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1711 - dice_coefficient: 0.9129\n",
      "Epoch 00020: loss did not improve from 0.17048\n",
      "409/409 [==============================] - 512s 1s/step - loss: 0.1711 - dice_coefficient: 0.9129 - lr: 1.0000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7ff8b4dbd048>"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x= X_train, y= masks, epochs=20, batch_size=1, verbose=1, callbacks = [checkpoint, stop, reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iVmOLDETAJWl"
   },
   "outputs": [],
   "source": [
    "# load the last saved weights\n",
    "model.load_weights('model-0.17.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "BfERV-5-AO9L",
    "outputId": "69010dc4-3f21-44c8-950a-5219e69d8311"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "Epoch 1/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1713 - dice_coefficient: 0.9128\n",
      "Epoch 00001: loss improved from inf to 0.17126, saving model to model-0.17.h5\n",
      "409/409 [==============================] - 544s 1s/step - loss: 0.1713 - dice_coefficient: 0.9128 - lr: 1.0000e-04\n",
      "Epoch 2/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1742 - dice_coefficient: 0.9115\n",
      "Epoch 00002: loss did not improve from 0.17126\n",
      "409/409 [==============================] - 544s 1s/step - loss: 0.1742 - dice_coefficient: 0.9115 - lr: 1.0000e-04\n",
      "Epoch 3/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1750 - dice_coefficient: 0.9112\n",
      "Epoch 00003: loss did not improve from 0.17126\n",
      "409/409 [==============================] - 543s 1s/step - loss: 0.1750 - dice_coefficient: 0.9112 - lr: 1.0000e-04\n",
      "Epoch 4/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1727 - dice_coefficient: 0.9127\n",
      "Epoch 00004: loss did not improve from 0.17126\n",
      "409/409 [==============================] - 543s 1s/step - loss: 0.1727 - dice_coefficient: 0.9127 - lr: 1.0000e-04\n",
      "Epoch 5/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1706 - dice_coefficient: 0.9135\n",
      "Epoch 00005: loss improved from 0.17126 to 0.17060, saving model to model-0.17.h5\n",
      "409/409 [==============================] - 543s 1s/step - loss: 0.1706 - dice_coefficient: 0.9135 - lr: 1.0000e-04\n",
      "Epoch 6/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1694 - dice_coefficient: 0.9142\n",
      "Epoch 00006: loss improved from 0.17060 to 0.16944, saving model to model-0.17.h5\n",
      "409/409 [==============================] - 543s 1s/step - loss: 0.1694 - dice_coefficient: 0.9142 - lr: 1.0000e-04\n",
      "Epoch 7/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1703 - dice_coefficient: 0.9135\n",
      "Epoch 00007: loss did not improve from 0.16944\n",
      "409/409 [==============================] - 542s 1s/step - loss: 0.1703 - dice_coefficient: 0.9135 - lr: 1.0000e-04\n",
      "Epoch 8/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1712 - dice_coefficient: 0.9132\n",
      "Epoch 00008: loss did not improve from 0.16944\n",
      "409/409 [==============================] - 540s 1s/step - loss: 0.1712 - dice_coefficient: 0.9132 - lr: 1.0000e-04\n",
      "Epoch 9/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1709 - dice_coefficient: 0.9135\n",
      "Epoch 00009: loss did not improve from 0.16944\n",
      "409/409 [==============================] - 540s 1s/step - loss: 0.1709 - dice_coefficient: 0.9135 - lr: 1.0000e-04\n",
      "Epoch 10/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1693 - dice_coefficient: 0.9144\n",
      "Epoch 00010: loss improved from 0.16944 to 0.16930, saving model to model-0.17.h5\n",
      "409/409 [==============================] - 541s 1s/step - loss: 0.1693 - dice_coefficient: 0.9144 - lr: 1.0000e-04\n",
      "Epoch 11/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1688 - dice_coefficient: 0.9146\n",
      "Epoch 00011: loss improved from 0.16930 to 0.16881, saving model to model-0.17.h5\n",
      "409/409 [==============================] - 541s 1s/step - loss: 0.1688 - dice_coefficient: 0.9146 - lr: 1.0000e-04\n",
      "Epoch 12/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1686 - dice_coefficient: 0.9148\n",
      "Epoch 00012: loss improved from 0.16881 to 0.16863, saving model to model-0.17.h5\n",
      "409/409 [==============================] - 541s 1s/step - loss: 0.1686 - dice_coefficient: 0.9148 - lr: 1.0000e-04\n",
      "Epoch 13/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1686 - dice_coefficient: 0.9147\n",
      "Epoch 00013: loss did not improve from 0.16863\n",
      "409/409 [==============================] - 540s 1s/step - loss: 0.1686 - dice_coefficient: 0.9147 - lr: 1.0000e-04\n",
      "Epoch 14/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1683 - dice_coefficient: 0.9150\n",
      "Epoch 00014: loss improved from 0.16863 to 0.16831, saving model to model-0.17.h5\n",
      "409/409 [==============================] - 541s 1s/step - loss: 0.1683 - dice_coefficient: 0.9150 - lr: 1.0000e-04\n",
      "Epoch 15/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1681 - dice_coefficient: 0.9153\n",
      "Epoch 00015: loss improved from 0.16831 to 0.16813, saving model to model-0.17.h5\n",
      "409/409 [==============================] - 553s 1s/step - loss: 0.1681 - dice_coefficient: 0.9153 - lr: 1.0000e-04\n",
      "Epoch 16/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1681 - dice_coefficient: 0.9152\n",
      "Epoch 00016: loss improved from 0.16813 to 0.16806, saving model to model-0.17.h5\n",
      "409/409 [==============================] - 554s 1s/step - loss: 0.1681 - dice_coefficient: 0.9152 - lr: 1.0000e-04\n",
      "Epoch 17/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1677 - dice_coefficient: 0.9155\n",
      "Epoch 00017: loss improved from 0.16806 to 0.16772, saving model to model-0.17.h5\n",
      "409/409 [==============================] - 554s 1s/step - loss: 0.1677 - dice_coefficient: 0.9155 - lr: 1.0000e-04\n",
      "Epoch 18/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1664 - dice_coefficient: 0.9163\n",
      "Epoch 00018: loss improved from 0.16772 to 0.16635, saving model to model-0.17.h5\n",
      "409/409 [==============================] - 553s 1s/step - loss: 0.1664 - dice_coefficient: 0.9163 - lr: 1.0000e-04\n",
      "Epoch 19/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1661 - dice_coefficient: 0.9163\n",
      "Epoch 00019: loss improved from 0.16635 to 0.16613, saving model to model-0.17.h5\n",
      "409/409 [==============================] - 552s 1s/step - loss: 0.1661 - dice_coefficient: 0.9163 - lr: 1.0000e-04\n",
      "Epoch 20/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1665 - dice_coefficient: 0.9162\n",
      "Epoch 00020: loss did not improve from 0.16613\n",
      "409/409 [==============================] - 553s 1s/step - loss: 0.1665 - dice_coefficient: 0.9162 - lr: 1.0000e-04\n",
      "Epoch 21/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1665 - dice_coefficient: 0.9162\n",
      "Epoch 00021: loss did not improve from 0.16613\n",
      "409/409 [==============================] - 552s 1s/step - loss: 0.1665 - dice_coefficient: 0.9162 - lr: 1.0000e-04\n",
      "Epoch 22/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1658 - dice_coefficient: 0.9168\n",
      "Epoch 00022: loss improved from 0.16613 to 0.16575, saving model to model-0.17.h5\n",
      "409/409 [==============================] - 553s 1s/step - loss: 0.1658 - dice_coefficient: 0.9168 - lr: 1.0000e-04\n",
      "Epoch 23/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1653 - dice_coefficient: 0.9168\n",
      "Epoch 00023: loss improved from 0.16575 to 0.16534, saving model to model-0.17.h5\n",
      "409/409 [==============================] - 555s 1s/step - loss: 0.1653 - dice_coefficient: 0.9168 - lr: 1.0000e-04\n",
      "Epoch 24/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1654 - dice_coefficient: 0.9168\n",
      "Epoch 00024: loss did not improve from 0.16534\n",
      "409/409 [==============================] - 556s 1s/step - loss: 0.1654 - dice_coefficient: 0.9168 - lr: 1.0000e-04\n",
      "Epoch 25/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1652 - dice_coefficient: 0.9169\n",
      "Epoch 00025: loss improved from 0.16534 to 0.16519, saving model to model-0.17.h5\n",
      "409/409 [==============================] - 558s 1s/step - loss: 0.1652 - dice_coefficient: 0.9169 - lr: 1.0000e-04\n",
      "Epoch 26/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1648 - dice_coefficient: 0.9173\n",
      "Epoch 00026: loss improved from 0.16519 to 0.16479, saving model to model-0.16.h5\n",
      "409/409 [==============================] - 557s 1s/step - loss: 0.1648 - dice_coefficient: 0.9173 - lr: 1.0000e-04\n",
      "Epoch 27/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1649 - dice_coefficient: 0.9173\n",
      "Epoch 00027: loss did not improve from 0.16479\n",
      "409/409 [==============================] - 551s 1s/step - loss: 0.1649 - dice_coefficient: 0.9173 - lr: 1.0000e-04\n",
      "Epoch 28/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1638 - dice_coefficient: 0.9179\n",
      "Epoch 00028: loss improved from 0.16479 to 0.16379, saving model to model-0.16.h5\n",
      "409/409 [==============================] - 556s 1s/step - loss: 0.1638 - dice_coefficient: 0.9179 - lr: 1.0000e-04\n",
      "Epoch 29/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1634 - dice_coefficient: 0.9181\n",
      "Epoch 00029: loss improved from 0.16379 to 0.16341, saving model to model-0.16.h5\n",
      "409/409 [==============================] - 556s 1s/step - loss: 0.1634 - dice_coefficient: 0.9181 - lr: 1.0000e-04\n",
      "Epoch 30/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1632 - dice_coefficient: 0.9183\n",
      "Epoch 00030: loss improved from 0.16341 to 0.16324, saving model to model-0.16.h5\n",
      "409/409 [==============================] - 557s 1s/step - loss: 0.1632 - dice_coefficient: 0.9183 - lr: 1.0000e-04\n",
      "Epoch 31/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1635 - dice_coefficient: 0.9181\n",
      "Epoch 00031: loss did not improve from 0.16324\n",
      "409/409 [==============================] - 555s 1s/step - loss: 0.1635 - dice_coefficient: 0.9181 - lr: 1.0000e-04\n",
      "Epoch 32/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1637 - dice_coefficient: 0.9180\n",
      "Epoch 00032: loss did not improve from 0.16324\n",
      "409/409 [==============================] - 556s 1s/step - loss: 0.1637 - dice_coefficient: 0.9180 - lr: 1.0000e-04\n",
      "Epoch 33/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1633 - dice_coefficient: 0.9182\n",
      "Epoch 00033: loss did not improve from 0.16324\n",
      "409/409 [==============================] - 557s 1s/step - loss: 0.1633 - dice_coefficient: 0.9182 - lr: 1.0000e-04\n",
      "Epoch 34/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1628 - dice_coefficient: 0.9187\n",
      "Epoch 00034: loss improved from 0.16324 to 0.16281, saving model to model-0.16.h5\n",
      "409/409 [==============================] - 557s 1s/step - loss: 0.1628 - dice_coefficient: 0.9187 - lr: 1.0000e-04\n",
      "Epoch 35/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1639 - dice_coefficient: 0.9180\n",
      "Epoch 00035: loss did not improve from 0.16281\n",
      "409/409 [==============================] - 554s 1s/step - loss: 0.1639 - dice_coefficient: 0.9180 - lr: 1.0000e-04\n",
      "Epoch 36/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1650 - dice_coefficient: 0.9173\n",
      "Epoch 00036: loss did not improve from 0.16281\n",
      "409/409 [==============================] - 554s 1s/step - loss: 0.1650 - dice_coefficient: 0.9173 - lr: 1.0000e-04\n",
      "Epoch 37/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1634 - dice_coefficient: 0.9182\n",
      "Epoch 00037: loss did not improve from 0.16281\n",
      "409/409 [==============================] - 554s 1s/step - loss: 0.1634 - dice_coefficient: 0.9182 - lr: 1.0000e-04\n",
      "Epoch 38/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1623 - dice_coefficient: 0.9189\n",
      "Epoch 00038: loss improved from 0.16281 to 0.16230, saving model to model-0.16.h5\n",
      "409/409 [==============================] - 557s 1s/step - loss: 0.1623 - dice_coefficient: 0.9189 - lr: 1.0000e-04\n",
      "Epoch 39/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1619 - dice_coefficient: 0.9190\n",
      "Epoch 00039: loss improved from 0.16230 to 0.16194, saving model to model-0.16.h5\n",
      "409/409 [==============================] - 555s 1s/step - loss: 0.1619 - dice_coefficient: 0.9190 - lr: 1.0000e-04\n",
      "Epoch 40/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1598 - dice_coefficient: 0.9203\n",
      "Epoch 00040: loss improved from 0.16194 to 0.15980, saving model to model-0.16.h5\n",
      "409/409 [==============================] - 554s 1s/step - loss: 0.1598 - dice_coefficient: 0.9203 - lr: 1.0000e-04\n",
      "Epoch 41/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1590 - dice_coefficient: 0.9207\n",
      "Epoch 00041: loss improved from 0.15980 to 0.15902, saving model to model-0.16.h5\n",
      "409/409 [==============================] - 554s 1s/step - loss: 0.1590 - dice_coefficient: 0.9207 - lr: 1.0000e-04\n",
      "Epoch 42/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1591 - dice_coefficient: 0.9206\n",
      "Epoch 00042: loss did not improve from 0.15902\n",
      "409/409 [==============================] - 553s 1s/step - loss: 0.1591 - dice_coefficient: 0.9206 - lr: 1.0000e-04\n",
      "Epoch 43/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1600 - dice_coefficient: 0.9202\n",
      "Epoch 00043: loss did not improve from 0.15902\n",
      "409/409 [==============================] - 555s 1s/step - loss: 0.1600 - dice_coefficient: 0.9202 - lr: 1.0000e-04\n",
      "Epoch 44/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1606 - dice_coefficient: 0.9200\n",
      "Epoch 00044: loss did not improve from 0.15902\n",
      "409/409 [==============================] - 554s 1s/step - loss: 0.1606 - dice_coefficient: 0.9200 - lr: 1.0000e-04\n",
      "Epoch 45/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1606 - dice_coefficient: 0.9201\n",
      "Epoch 00045: loss did not improve from 0.15902\n",
      "409/409 [==============================] - 556s 1s/step - loss: 0.1606 - dice_coefficient: 0.9201 - lr: 1.0000e-04\n",
      "Epoch 46/50\n",
      "409/409 [==============================] - ETA: 0s - loss: 0.1606 - dice_coefficient: 0.9201\n",
      "Epoch 00046: loss did not improve from 0.15902\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "409/409 [==============================] - 557s 1s/step - loss: 0.1606 - dice_coefficient: 0.9201 - lr: 1.0000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7efec81e8080>"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# contrinue training\n",
    "checkpoint = ModelCheckpoint(\"model-{loss:.2f}.h5\", monitor=\"loss\", verbose=1, save_best_only=True,\n",
    "                             save_weights_only=True, mode=\"min\", period=1)\n",
    "stop = EarlyStopping(monitor=\"loss\", patience=5, mode=\"min\")\n",
    "reduce_lr = ReduceLROnPlateau(monitor=\"loss\", factor=0.2, patience=5, min_lr=1e-6, verbose=1, mode=\"min\")\n",
    "\n",
    "model.fit(x= X_train, y= masks, epochs=50, batch_size=1, verbose=1, callbacks = [checkpoint, stop, reduce_lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The final model has a dice coefficient of 0.92 and loss of 0.1606. Let's predict the mask for a sample image using the model trained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JpLC-e-2sg8A"
   },
   "source": [
    "***Get the predicted mask for a sample image***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "Tv-_9NMesf65",
    "outputId": "2f7162d9-365d-47aa-e80e-12943be77a5a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7efec4bf6e48>"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 10\n",
    "sample_image = X_train[n]\n",
    "\n",
    "#model.load_weights('model-0.16.h5')\n",
    "pred_mask = cv2.resize(1.0*(model.predict(x=np.array([sample_image]))[0] > 0.5), (IMAGE_WIDTH,IMAGE_HEIGHT))\n",
    "\n",
    "pyplot.imshow(pred_mask)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yf0n9RJG80kR"
   },
   "source": [
    "**Impose the mask on the image**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "id": "rvECQuhKhKII",
    "outputId": "55ba4f07-39a6-4ed7-de13-e12b95b68e24"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7efec4b806d8>"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = data[n][0]\n",
    "\n",
    "image = cv2.resize(img, (IMAGE_WIDTH, IMAGE_HEIGHT))\n",
    "img_scaled = preprocess_input(np.array(image, dtype=np.float32))\n",
    "\n",
    "pred_mask = cv2.resize(1.0*(model.predict(x=np.array([img_scaled]))[0] > 0.5), (IMAGE_WIDTH,IMAGE_HEIGHT))\n",
    "\n",
    "image2 = image\n",
    "image2[:,:,0] = pred_mask*image[:,:,0]\n",
    "image2[:,:,1] = pred_mask*image[:,:,1]\n",
    "image2[:,:,2] = pred_mask*image[:,:,2]\n",
    "\n",
    "out_image = image2\n",
    "\n",
    "pyplot.imshow(out_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The mask is imposed on the original image and output is shown above"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "cv_project1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
